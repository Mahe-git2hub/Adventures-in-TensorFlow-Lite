{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TUNIT Conversion to TF Lite",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayakpaul/Adventures-in-TensorFlow-Lite/blob/master/TUNIT_Conversion_to_TF_Lite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD1hCGUh0ap6",
        "colab_type": "text"
      },
      "source": [
        "This notebook presents a demo of the TUNIT paper ([Rethinking the Truly Unsupervised Image-to-Image Translation](https://arxiv.org/abs/2006.06500)). GitHub repo of the paper can be found [here](https://github.com/clovaai/tunit). It also demonstrates the process of converting PyTorch models to TF Lite using ONNX. \n",
        "\n",
        "![](https://github.com/clovaai/tunit/raw/master/resrc/teaser_3row.png)\n",
        "\n",
        "<center>Source: Original Paper</center>\n",
        "\n",
        "Note that the predictions from the converted TF Lite models look faulty. But this notebook still might serve as a reference for the conversion worflow. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIQ-t4EIr89C",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSg9xKz5Xv5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9UipQQ3zUCz",
        "colab_type": "text"
      },
      "source": [
        "Please note that we used the **animalFaces10_1_00** pre-trained checkpoints. I first copied the files from [here](https://drive.google.com/drive/folders/1rU1B9OLQjYMBzU6VQX7UwLxod2WzOfNz?usp=sharing) to my personal Drive, created a folder called animalFaces10_0_00, and copied the files to that folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Knoxd8MXX7ma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/clovaai/tunit/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjPq8kHiX_Xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd tunit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXHQyFMFXyO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from models.generator import Generator\n",
        "from models.guidingNet import GuidingNet\n",
        "import torch.nn.functional as F\n",
        "import torchvision.utils as vutils\n",
        "from PIL import Image\n",
        "from torchvision.transforms import ToTensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoJwDt9HzlPi",
        "colab_type": "text"
      },
      "source": [
        "## Instantiating the model classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7diB4ChuYEjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "G = Generator(128, 128)\n",
        "C = GuidingNet(128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDKb6Y9bYNU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /content/drive/My\\ Drive/animalFaces10_1_00 ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAyORqAGYgZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -lh animalFaces10_1_00"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7exoadoHzpm3",
        "colab_type": "text"
      },
      "source": [
        "## Loading the checkpoints in the model classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hoiXZtOYJlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_file = 'animalFaces10_1_00/model_4568.ckpt'\n",
        "checkpoint = torch.load(load_file, map_location='cpu')\n",
        "G.load_state_dict(checkpoint['G_EMA_state_dict'])\n",
        "C.load_state_dict(checkpoint['C_EMA_state_dict'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7kwdN4-sjDo",
        "colab_type": "text"
      },
      "source": [
        "The reference image must be an image from a domain included in the training. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_BI0Dg5ztNd",
        "colab_type": "text"
      },
      "source": [
        "## Gather images for running inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MeaD2qZY03P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -O source.jpg https://github.com/NVlabs/FUNIT/raw/master/images/input_content.jpg\n",
        "!wget -O reference.jpg https://user-images.githubusercontent.com/23406491/84877309-4e7abf80-b0c3-11ea-8f2d-b18d398e9584.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWltlvU8zyBo",
        "colab_type": "text"
      },
      "source": [
        "## Prepare the images and then run inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8aiG33QYrqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "G.eval()\n",
        "C.eval()\n",
        "\n",
        "source_image = Image.open('source.jpg')\n",
        "reference_image = Image.open('reference.jpg')\n",
        "\n",
        "x_src = ToTensor()(source_image).unsqueeze(0)\n",
        "x_ref = ToTensor()(reference_image).unsqueeze(0)\n",
        "\n",
        "x_src = F.interpolate(x_src, size=(128, 128))\n",
        "x_ref = F.interpolate(x_ref, size=(128, 128))\n",
        "\n",
        "x_src = (x_src - 0.5) / 0.5\n",
        "x_ref = (x_ref - 0.5) / 0.5\n",
        "\n",
        "s_ref = C.moco(x_ref)\n",
        "x_res = G(x_src, s_ref)\n",
        "\n",
        "vutils.save_image(x_res, 'test_out.jpg', normalize=True, padding=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXtz-ve5z1U5",
        "colab_type": "text"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTFaDSnQaTWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZrlPz1za0Mf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(pil_image, title=None):\n",
        "    np_array = np.asarray(pil_image)\n",
        "    plt.imshow(np_array)\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "imshow(source_image, 'Source Image')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "imshow(reference_image, 'Reference Image')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "result = Image.open('test_out.jpg')\n",
        "imshow(result, 'Transformed Image')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_ortYTOeOOC",
        "colab_type": "text"
      },
      "source": [
        "## Set up `onnx-tf`\n",
        "\n",
        "Reference: https://towardsdatascience.com/onnx-made-easy-957e60d16e94/ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HXVg371c4sI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/tunit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrUKMVFTdmgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf \n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ7-7mcYdsns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgbKXN-d0b2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/onnx/onnx-tensorflow.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG3MneOTeBZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsSeso2beG0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd onnx-tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6VSfQx6d43E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install -e ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Maqu-Yx_fHNP",
        "colab_type": "text"
      },
      "source": [
        "## Convert to TensorFlow graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYiixxyreW_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import onnx\n",
        "from onnx_tf.backend import prepare"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R75SMa_eZvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Export the generator\n",
        "torch.onnx.export(G, (x_src, s_ref), 'generator.onnx', input_names=['test_input', 'style_input'], output_names=['test_output'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0dgjWapepFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Export the encoder\n",
        "torch.onnx.export(C, x_ref, 'encoder.onnx', input_names=['test_input'], output_names=['test_output'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuTH13gues0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_tf_graph(onnx_file, tf_graph_file):\n",
        "    # Load ONNX model and convert to TensorFlow format\n",
        "    onnx_module = onnx.load(onnx_file)\n",
        "    tf_rep = prepare(onnx_module)\n",
        "\n",
        "    # Export model as .pb file\n",
        "    tf_rep.export_graph(tf_graph_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG-agx_5e5z6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate the TF Graph of the generator onnx module\n",
        "generate_tf_graph('generator.onnx', 'generator.pb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzN_i5z9fw3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate the TF Graph of the encoder onnx module\n",
        "generate_tf_graph('encoder.onnx', 'encoder.pb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpBthG-w6Yi4",
        "colab_type": "text"
      },
      "source": [
        "Ignore the warnings. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNwgKsrnkm4X",
        "colab_type": "text"
      },
      "source": [
        "## Inspect the TF graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC3DCpvmizmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_pb(path_to_pb):\n",
        "    with tf.io.gfile.GFile(path_to_pb, 'rb') as f:\n",
        "        graph_def = tf.compat.v1.GraphDef()\n",
        "        graph_def.ParseFromString(f.read())\n",
        "    with tf.Graph().as_default() as graph:\n",
        "        tf.import_graph_def(graph_def, name='')\n",
        "        return graph\n",
        "\n",
        "def show_ops(path_to_pb):\n",
        "    tf_graph = load_pb(path_to_pb)\n",
        "\n",
        "    for op in tf_graph.get_operations():\n",
        "        print(op.values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaIcQRQujEwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_ops('generator.pb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6N4whATkMK9",
        "colab_type": "text"
      },
      "source": [
        "Output to note: `(<tf.Tensor 'test_output:0' shape=(1, 3, 128, 128) dtype=float32>,)`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAB2yPh6juzx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_ops('encoder.pb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8L7lj7gkHXf",
        "colab_type": "text"
      },
      "source": [
        "Output to note: `(<tf.Tensor 'test_output:0' shape=(1, 128) dtype=float32>,)`. It also matches with the dimensions of `s_ref` which is the output we got when we ran `C.moco(x_ref)`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dBejRLckrLE",
        "colab_type": "text"
      },
      "source": [
        "## Convert to TF Lite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5F_bZ4f6eJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# During writing this tutorial the Flex ops were only supported via tf-nightly in the Python interpreter\n",
        "!pip uninstall -q tensorflow\n",
        "!pip install -q tf-nightly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8PEGJ3mDIL4",
        "colab_type": "text"
      },
      "source": [
        "Restart the runtime at this point. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZoOLTI0lc2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tempfile\n",
        "import tensorflow as tf \n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjkuq_Z2ku2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_tflite(tf_graph, input_arrays):\n",
        "    converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(\n",
        "        graph_def_file=tf_graph, \n",
        "        input_arrays=input_arrays,\n",
        "        output_arrays=['test_output']\n",
        "    )\n",
        "\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "                                        tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "\n",
        "    # Convert to TFLite Model\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    _, tflite_path = tempfile.mkstemp('.tflite')\n",
        "    tflite_model_size = open(tflite_path, 'wb').write(tflite_model)\n",
        "    tf_model_size = os.path.getsize(tf_graph)\n",
        "    print('TensorFlow Model is  {} bytes'.format(tf_model_size))\n",
        "    print('TFLite Model is      {} bytes'.format(tflite_model_size))\n",
        "    print('Post training dynamic range quantization saves {} bytes'.format(tf_model_size-tflite_model_size))\n",
        "    print('Saved TF Lite model to: {}'.format(tflite_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvMG09O5mbWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "convert_to_tflite('/content/tunit/onnx-tensorflow/generator.pb', ['test_input', 'style_input'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlcM6-sZmjh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "convert_to_tflite('/content/tunit/onnx-tensorflow/encoder.pb', ['test_input'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA9McGsDmo_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please update the TF Lite file paths from the above before running this cell\n",
        "!cp /tmp/tmpbhh77i06.tflite generator.tflite\n",
        "!cp /tmp/tmp6144a9n1.tflite encoder.tflite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S8n8iuLnERd",
        "colab_type": "text"
      },
      "source": [
        "## Download the TF Lite files (optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4LV4KjUm4-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the TF Lite files \n",
        "from google.colab import files\n",
        "files.download('generator.tflite')\n",
        "files.download('encoder.tflite')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTfRMyMAnu3s",
        "colab_type": "text"
      },
      "source": [
        "## Running inference with TF Lite "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cbrc4g9qGuid",
        "colab_type": "text"
      },
      "source": [
        "### Inspect the model inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-ybtx16nOdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_tflite_model(tflite_model_path):\n",
        "    # Load the model.\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "\n",
        "    # Set model input.\n",
        "    input_details = interpreter.get_input_details()\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    # Get image size - converting from BCHW to WH\n",
        "    input_size = input_details[0]['shape'][3], input_details[0]['shape'][2]\n",
        "    print('Input size of {} model: {}'.format(tflite_model_path, input_size))\n",
        "\n",
        "    if tflite_model_path == 'generator.tflite':\n",
        "        style_reference_size = input_details[1]['shape'][0], input_details[1]['shape'][1]\n",
        "        print('Style reference size of {} model: {}'.format(tflite_model_path, style_reference_size))\n",
        "\n",
        "    return (interpreter, input_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi7bXibX80J2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TF Lite models in the Python TF Lite interpreter\n",
        "generator_inter, _ = load_tflite_model('generator.tflite')\n",
        "encoder_inter, _ = load_tflite_model('encoder.tflite')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9W8Mrk9RGywG",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the images for inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq29_Uts9_ZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy over the sample images to perform inference\n",
        "!cp /content/tunit/source.jpg .\n",
        "!cp /content/tunit/reference.jpg ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKElcsde-vqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utility to prepare the images\n",
        "# We need to match the steps that were performed above\n",
        "def load_img(path_to_img, reshape_size=(128, 128)):\n",
        "    img = tf.io.read_file(path_to_img)\n",
        "    img = tf.io.decode_image(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = img[tf.newaxis, :]\n",
        "\n",
        "    img = tf.image.resize(img, reshape_size, method='nearest')\n",
        "    img = (img - 0.5) / 0.5\n",
        "    \n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvSXvB2K_pq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare the images\n",
        "x_src = load_img('source.jpg')\n",
        "x_ref = load_img('reference.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jewazmJG_vDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_src.shape, x_ref.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4Rh_jwJAJnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The TF Lite models have an input shape of (1, 3, 128, 128)\n",
        "x_src_reshaped = tf.reshape(x_src, (1, 3, 128, 128))\n",
        "x_ref_reshaped = tf.reshape(x_ref, (1, 3, 128, 128))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kcyp6chG3N1",
        "colab_type": "text"
      },
      "source": [
        "### Run inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsnF3eeQBZxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to run style prediction on preprocessed style image.\n",
        "# Reference: https://www.tensorflow.org/lite/models/style_transfer/overview#style_transform\n",
        "def run_style_predict(reference_img, tflite_path):\n",
        "    # Load the model.\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "\n",
        "    # Set model input.\n",
        "    interpreter.allocate_tensors()\n",
        "    input_details = interpreter.get_input_details()\n",
        "    interpreter.set_tensor(input_details[0][\"index\"], reference_img)\n",
        "\n",
        "    # Calculate style bottleneck.\n",
        "    interpreter.invoke()\n",
        "    style_bottleneck = interpreter.tensor(\n",
        "        interpreter.get_output_details()[0][\"index\"]\n",
        "        )()\n",
        "\n",
        "    return style_bottleneck\n",
        "\n",
        "# Calculate style bottleneck for the preprocessed style image.\n",
        "style_bottleneck = run_style_predict(x_ref_reshaped, 'encoder.tflite')\n",
        "print('Style Bottleneck Shape:', style_bottleneck.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0KwNzItEeTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run style transform on preprocessed style image\n",
        "# Reference: https://www.tensorflow.org/lite/models/style_transfer/overview#style_transform\n",
        "def run_style_transform(style_bottleneck, preprocessed_source_image, tflite_path):\n",
        "  # Load the model.\n",
        "  interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "\n",
        "  # Set model input.\n",
        "  input_details = interpreter.get_input_details()\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  # Set model inputs.\n",
        "  interpreter.set_tensor(input_details[0][\"index\"], preprocessed_source_image)\n",
        "  interpreter.set_tensor(input_details[1][\"index\"], style_bottleneck)\n",
        "  interpreter.invoke()\n",
        "\n",
        "  # Transform content image.\n",
        "  stylized_image = interpreter.tensor(\n",
        "      interpreter.get_output_details()[0][\"index\"]\n",
        "      )()\n",
        "\n",
        "  return stylized_image\n",
        "\n",
        "# Transform the content image using the style bottleneck.\n",
        "resultant_image = run_style_transform(style_bottleneck, x_src_reshaped, 'generator.tflite')\n",
        "print('Resultant image shape:', resultant_image.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOTqQx6pGa7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize the resultant image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "resultant_image = tf.reshape(resultant_image, (1, 128, 128, 3))\n",
        "resultant_image = tf.squeeze(resultant_image)\n",
        "plt.imshow(tf.clip_by_value(resultant_image, 0., 1.))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEyqN75Oz511",
        "colab_type": "text"
      },
      "source": [
        "## Acknowledgements\n",
        "\n",
        "Thanks to [Kyungjune Baek](https://friedronaldo.github.io/hibkj/) for his guidance in running demo inference in PyTorch. "
      ]
    }
  ]
}